{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "import os, tomli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.streamlit/secrets.toml','rb') as f:\n",
    "    secrets = tomli.load(f)\n",
    "    \n",
    "api_key = secrets[\"MISTRAL_API_KEY\"]\n",
    "# api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-tiny\"\n",
    "\n",
    "client = MistralClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role='user', content='What is the best French cheese?')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"What is the best French cheese?\")\n",
    "]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is the best French cheese?'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat2struct(chat):\n",
    "    return [{'role': m.role, 'content': m.content} for m in chat]\n",
    "chat2struct(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [{'role': 'system', 'content': 'If I say hello, say world'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role='system', content='If I say hello, say world')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def struct2chat(struct):\n",
    "    return [ChatMessage(role=m['role'], content=m['content']) for m in struct]\n",
    "struct2chat(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(role='system', content='If I say hello, say world')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatMessage(role=m[0]['role'], content=m[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is subjective to determine the \"best\" French cheese as it depends on personal preferences. Some popular and highly regarded French cheeses are:\n",
      "\n",
      "1. Roquefort: A blue-veined cheese from the Massif Central region, known for its strong, pungent flavor and distinctive tang.\n",
      "\n",
      "2. Comté: A nutty, buttery, and slightly sweet cheese from the Franche-Comté region, made from unpasteurized cow's milk.\n",
      "\n",
      "3. Camembert de Normandie: A soft, Earthy, and tangy cheese from the Normandy region, famous for its white mold rind.\n",
      "\n",
      "4. Brie de Meaux: A creamy and mild soft-ripened cheese from the Île-de-France region, known for its edible white rind and rich, buttery flavor.\n",
      "\n",
      "5. Munster: A pungent and smelly cheese from the Alsace region, characterized by its orange-red rind and strong, distinctive flavor.\n",
      "\n",
      "6. Chaource: A bloomy-rind, mild, and creamy cheese from the Île-de-France region, with a slightly tangy taste and a buttery texture.\n",
      "\n",
      "7. Époisses de Bourgogne: A soft, smelly, and runny cheese from the Burgundy region, known for its pungent aroma and rich, savory flavor.\n",
      "\n",
      "Ultimately, the \"best\" French cheese depends on your personal taste preferences, so it's recommended to try a variety and find the one that suits you best.\n"
     ]
    }
   ],
   "source": [
    "# No streaming\n",
    "chat_response = client.chat(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webvtt-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, webvtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YannMike_2023-03-08.vtt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('vtt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'YannMike_2023-03-08.vtt'\n",
    "chat = webvtt.read('vtt/'+file)\n",
    "str = []\n",
    "for caption in chat:\n",
    "    str.append(caption.text)\n",
    "sep = '\\n'\n",
    "convo = sep.join(str)\n",
    "with open('txt/'+file.replace('vtt','txt'),mode='w') as f:\n",
    "    f.write(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "words = convo.split() # split the string into words \n",
    "num_tokens = math.floor(len(words) * 3/4) # 3/4 of the words are tokens\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker is planning to conduct an experiment where they record conversations and generate VTT files. They have developed a Python app to process these files and intend to use the ChatGPT API for analysis. However, they are having trouble finding time to implement this due to various commitments.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'summarize the following conversation'\n",
    "model = 'mistral-tiny'\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=context),\n",
    "    ChatMessage(role=\"user\", content=convo)\n",
    "]\n",
    "# messages = [\n",
    "#         {'role': 'system','content': context},\n",
    "#         {'role': 'user', 'content': convo}\n",
    "#             ]\n",
    "completion = client.chat(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
